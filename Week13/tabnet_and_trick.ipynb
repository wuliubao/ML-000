{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tabnet_and_trick.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPg0Q4daI7a5HW0w73IiUKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b952f00de2b46eebeee22db4a469b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_faa7e973d51b422cb641994b1dc06794",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc8c2c43f2aa42f5b9846ae4e4d7dd96",
              "IPY_MODEL_cb03de7071a94073a77dc9e0fb87b503"
            ]
          }
        },
        "faa7e973d51b422cb641994b1dc06794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bc8c2c43f2aa42f5b9846ae4e4d7dd96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24684ea444504721bcf3aa41b24f8518",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6c981f5386b4fa786cd01817b7f733d"
          }
        },
        "cb03de7071a94073a77dc9e0fb87b503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_758659a07bf841d3975c9e9a5a2301ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [01:54&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3f0778407ff4d7b98e0f11df37e9ef8"
          }
        },
        "24684ea444504721bcf3aa41b24f8518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6c981f5386b4fa786cd01817b7f733d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "758659a07bf841d3975c9e9a5a2301ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3f0778407ff4d7b98e0f11df37e9ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c565991532d14c5b822fe9e7be610272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86471e18997945f78b7c1ac1d43aebce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_902cfb83958146d38f7c923b68f98dba",
              "IPY_MODEL_d6b452f0cf70406695f165851e137b6a"
            ]
          }
        },
        "86471e18997945f78b7c1ac1d43aebce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "902cfb83958146d38f7c923b68f98dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90c54c8686a74850a32fa9fb881a77e5",
            "_dom_classes": [],
            "description": "Epoch 0: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2345,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2345,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43b9e25a1317414b9a48c610e071f28c"
          }
        },
        "d6b452f0cf70406695f165851e137b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d253a79ef5a4038a4e690390f1340f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2345/2345 [04:47&lt;00:00,  8.16it/s, loss=0.671, v_num=1]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6da4f4157ad842f7aaa6c31c85c0dd07"
          }
        },
        "90c54c8686a74850a32fa9fb881a77e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43b9e25a1317414b9a48c610e071f28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d253a79ef5a4038a4e690390f1340f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6da4f4157ad842f7aaa6c31c85c0dd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffa3a178f3684ca59c47631c61fad37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3aafcd3def1e407ea2600b29f04e410d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c28818fec9747dfa772578ce970a225",
              "IPY_MODEL_834d372ae9e04da2b20ad2336180ffc0"
            ]
          }
        },
        "3aafcd3def1e407ea2600b29f04e410d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5c28818fec9747dfa772578ce970a225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68cd09d3243f4f96917eed33eda47ae2",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f22588d490b144b8bb795d3927c2bc75"
          }
        },
        "834d372ae9e04da2b20ad2336180ffc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b9bffea29d34f2191faacf36ed86d7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 391/391 [00:28&lt;00:00, 13.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4554fc0a6f1c4d248ee5caee06201e05"
          }
        },
        "68cd09d3243f4f96917eed33eda47ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f22588d490b144b8bb795d3927c2bc75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b9bffea29d34f2191faacf36ed86d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4554fc0a6f1c4d248ee5caee06201e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc6fe724233a41c1857288f17307db8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e2bedd0b9294e2998a72bef0811a762",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2a498ccbaf74c70878a5ea4064a73fd",
              "IPY_MODEL_0f6721f741b043ebade758f437dbf086"
            ]
          }
        },
        "7e2bedd0b9294e2998a72bef0811a762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e2a498ccbaf74c70878a5ea4064a73fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2df067f76c348c888f4a7f77d20f039",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1773040140e4b96bdfc67b385733789"
          }
        },
        "0f6721f741b043ebade758f437dbf086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e352382cd36e4c468f17b37fbcfa6cb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 391/391 [00:29&lt;00:00, 13.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80f26de9e1d74bc0aa1e83408a20ef95"
          }
        },
        "c2df067f76c348c888f4a7f77d20f039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1773040140e4b96bdfc67b385733789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e352382cd36e4c468f17b37fbcfa6cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80f26de9e1d74bc0aa1e83408a20ef95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wuliubao/ML-000/blob/main/Week13/tabnet_and_trick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVhziJssW-P9"
      },
      "source": [
        "构建数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvBXB0c8C5T1"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "\n",
        "def encode_label(x):\n",
        "    unique=sorted(list(set([str(item) for item in np.unique(x)])))\n",
        "    kv = {unique[i]: i for i in range(len(unique))}\n",
        "    vfunc = np.vectorize(lambda x: kv[str(x)])\n",
        "    return vfunc(x)\n",
        "\n",
        "def encode_label_mat(x):\n",
        "    _, ncol = x.shape\n",
        "    result = np.empty_like(x, dtype=int)\n",
        "    for col in range(ncol):\n",
        "        result[:,col] = encode_label(x[:, col])\n",
        "    return result\n",
        "\n",
        "def impute_nan(x, method='median'):\n",
        "    _, ncol = x.shape\n",
        "    result = np.empty_like(x)\n",
        "\n",
        "    for col in range(ncol):\n",
        "        if method == 'median':\n",
        "            data = x[:, col]\n",
        "            impute_value = np.median(data[~pd.isnull(data) & (data != np.inf) & (data != -np.inf)])\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "        func = np.vectorize(lambda x: impute_value if pd.isnull(x) else x)\n",
        "        result[:, col] = func(x[:, col])\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_uniform_interval(minimum, maximum, nbins):\n",
        "    result = [minimum]\n",
        "    step_size = (float(maximum - minimum)) / nbins\n",
        "    for index in range(nbins - 1):\n",
        "        result.append(minimum + step_size * (index + 1))\n",
        "    result.append(maximum)\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_interval_v2(x, sorted_intervals):\n",
        "    if pd.isnull(x):\n",
        "        return -1\n",
        "    if x == np.inf:\n",
        "        return -2\n",
        "    if x == -np.inf:\n",
        "        return -3\n",
        "    interval = 0\n",
        "    found = False\n",
        "    sorted_intervals.append(np.inf)\n",
        "    while not found and interval < len(sorted_intervals) - 1:\n",
        "        if sorted_intervals[interval] <= x < sorted_intervals[interval + 1]:\n",
        "            return interval\n",
        "        else:\n",
        "            interval += 1\n",
        "\n",
        "\n",
        "def get_quantile_interval(data, nbins):\n",
        "    quantiles = get_uniform_interval(0, 1, nbins)\n",
        "    return list(np.quantile(data[(~pd.isnull(data)) & (data != np.inf) & (data != -np.inf)], quantiles))\n",
        "\n",
        "\n",
        "def discretize(x, nbins=20):\n",
        "    nrow, ncol = x.shape\n",
        "    result = np.empty_like(x)\n",
        "    interval_list = list()\n",
        "    for col in range(ncol):\n",
        "        intervals = sorted(list(set(get_quantile_interval(x[:, col], nbins))))\n",
        "        interval_centroid = list()\n",
        "\n",
        "        for i in range(len(intervals) - 1):\n",
        "            interval_centroid.append(0.5 * (intervals[i] + intervals[i + 1]))\n",
        "        func = np.vectorize(lambda x: get_interval_v2(x, intervals))\n",
        "        result[:, col] = encode_label(func(x[:, col]))\n",
        "        interval_list.append(interval_centroid)\n",
        "    return result.astype(np.int64), interval_list\n",
        "\n",
        "def get_var_type(df):\n",
        "    columns = df.columns\n",
        "    continuous_vars = [x for x in columns if x.startswith('continuous_')]\n",
        "    discrete_vars = [x for x in columns if x.startswith('discrete_')]\n",
        "    other_vars = list()\n",
        "    for column in columns:\n",
        "        if column not in continuous_vars and column not in discrete_vars:\n",
        "            other_vars.append(column)\n",
        "    return {'continuous': continuous_vars,\n",
        "            'discrete': discrete_vars,\n",
        "            'other': other_vars}\n",
        "\n",
        "\n",
        "def get_cont_var(df):\n",
        "    var_types = get_var_type(df)\n",
        "    return var_types['continuous']\n",
        "\n",
        "\n",
        "def get_dis_var(df):\n",
        "    var_types = get_var_type(df)\n",
        "    return var_types['discrete']\n",
        "\n",
        "def drop_const_var(data):\n",
        "    result = data.copy(deep=True)\n",
        "    for col in data.columns:\n",
        "        if len(data.loc[~pd.isnull(data[col]), col].unique()) <= 1:\n",
        "            result.drop(columns=col, inplace=True)\n",
        "    return result\n",
        "\n",
        "x_1 = torch.randn(100000)\n",
        "x_2 = torch.randn(100000)\n",
        "x_useful = torch.cos(1.5*x_1)*(x_2**2)\n",
        "x_1_rest_small = torch.randn(100000, 15)+ 0.01*x_1.unsqueeze(1)\n",
        "x_1_rest_large = torch.randn(100000, 15) + 0.1*x_1.unsqueeze(1)\n",
        "x_2_rest_small = torch.randn(100000, 15)+ 0.01*x_2.unsqueeze(1)\n",
        "x_2_rest_large = torch.randn(100000, 15) + 0.1*x_2.unsqueeze(1)\n",
        "x = torch.cat([x_1[:, None], x_2[:, None], x_1_rest_small, x_1_rest_large, x_2_rest_small, x_2_rest_large], dim=1)\n",
        "y = ((10*x_useful) + 5*torch.randn(100000) >0.0).type(torch.int64) \n",
        "\n",
        "x_train, x_test = x[:50000, :], x[50000:, :]\n",
        "y_train, y_test = y[:50000], y[50000:]\n",
        "x_train_np, x_test_np = x_train.numpy(), x_test.numpy()\n",
        "y_train_np, y_test_np = y_train.numpy(), y_test.numpy()\n",
        "x = np.concatenate([x_train_np, x_test_np])\n",
        "x_dis, centroids = discretize(x)\n",
        "x_dis_train = x_dis[:50000, :]\n",
        "x_dis_test = x_dis[50000:,:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-fSPwVCYLzM"
      },
      "source": [
        "Mask相关定义"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsqLEmkuYhMk"
      },
      "source": [
        "from torch import nn\n",
        "from torch.autograd import Function\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "def _make_ix_like(input, dim=0):\n",
        "    d = input.size(dim)\n",
        "    rho = torch.arange(1, d + 1, device=input.device, dtype=input.dtype)\n",
        "    view = [1] * input.dim()\n",
        "    view[0] = -1\n",
        "    return rho.view(view).transpose(0, dim)\n",
        "\n",
        "\n",
        "class SparsemaxFunction(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, dim=-1):\n",
        "\n",
        "        ctx.dim = dim\n",
        "        max_val, _ = input.max(dim=dim, keepdim=True)\n",
        "        input -= max_val  # same numerical stability trick as for softmax\n",
        "        tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n",
        "        output = torch.clamp(input - tau, min=0)\n",
        "        ctx.save_for_backward(supp_size, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        supp_size, output = ctx.saved_tensors\n",
        "        dim = ctx.dim\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[output == 0] = 0\n",
        "\n",
        "        v_hat = (grad_input.sum(dim=dim) / supp_size).squeeze()\n",
        "        v_hat = v_hat.unsqueeze(dim)\n",
        "        grad_input = torch.where(output != 0, grad_input - v_hat, grad_input)\n",
        "        return grad_input, None\n",
        "\n",
        "    @staticmethod\n",
        "    def _threshold_and_support(input, dim=-1):\n",
        "        input_srt, _ = torch.sort(input, descending=True, dim=dim)\n",
        "        input_cumsum = input_srt.cumsum(dim) - 1\n",
        "        rhos = _make_ix_like(input, dim)\n",
        "        support = rhos * input_srt > input_cumsum\n",
        "\n",
        "        support_size = support.sum(dim=dim).unsqueeze(dim)\n",
        "        tau = input_cumsum.gather(dim, support_size - 1)\n",
        "        tau /= support_size.to(input.dtype)\n",
        "        return tau, support_size\n",
        "\n",
        "sparsemax = SparsemaxFunction.apply\n",
        "\n",
        "class Sparsemax(nn.Module):\n",
        "\n",
        "    def __init__(self, dim=-1):\n",
        "        self.dim = dim\n",
        "        super(Sparsemax, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return sparsemax(input, self.dim)\n",
        "\n",
        "\n",
        "class Entmax15(nn.Module):\n",
        "    def __init__(self, dim=-1):\n",
        "        super().__init_()\n",
        "        self.dim=dim\n",
        "            \n",
        "    @staticmethod\n",
        "    def _threshold_and_support(input, dim=-1):\n",
        "        Xsrt, _ = torch.sort(input, descending=True, dim=dim)\n",
        "\n",
        "        rho = _make_ix_like(input, dim)\n",
        "        mean = Xsrt.cumsum(dim) / rho\n",
        "        mean_sq = (Xsrt ** 2).cumsum(dim) / rho\n",
        "        ss = rho * (mean_sq - mean ** 2)\n",
        "        delta = (1 - ss) / rho\n",
        "\n",
        "        delta_nz = torch.clamp(delta, 0)\n",
        "        tau = mean - torch.sqrt(delta_nz)\n",
        "\n",
        "        support_size = (tau <= Xsrt).sum(dim).unsqueeze(dim)\n",
        "        tau_star = tau.gather(dim, support_size - 1)\n",
        "        return tau_star, support_size\n",
        "    def forward(self, input):\n",
        "        max_val, _ = input.max(dim=self.dim, keepdim=True)\n",
        "        input = input - max_val  # same numerical stability trick as for softmax\n",
        "        input = input / 2  # divide by 2 to solve actual Entmax\n",
        "\n",
        "        tau_star, _ = Entmax15Function._threshold_and_support(input, self.dim)\n",
        "        output = torch.clamp(input - tau_star, min=0) ** 2\n",
        "        ctx.save_for_backward(output)\n",
        "        return output \n",
        "\n",
        "    def backward(self, output, grad):\n",
        "        Y = output\n",
        "        gppr = Y.sqrt()  # = 1 / g'' (Y)\n",
        "        dX = grad_output * gppr\n",
        "        q = dX.sum(ctx.dim) / gppr.sum(ctx.dim)\n",
        "        q = q.unsqueeze(ctx.dim)\n",
        "        dX -= q * gppr\n",
        "        return dX, None"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU-EPk6AZCr-"
      },
      "source": [
        "定义TabNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akK5OR2mZ5jr"
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch.nn import Linear, BatchNorm1d, ReLU\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "def initialize_non_glu(module, input_dim, output_dim):\n",
        "    gain_value = np.sqrt((input_dim+output_dim)/np.sqrt(4*input_dim))\n",
        "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
        "    # torch.nn.init.zeros_(module.bias)\n",
        "    return\n",
        "\n",
        "def initialize_glu(module, input_dim, output_dim):\n",
        "    gain_value = np.sqrt((input_dim+output_dim)/np.sqrt(input_dim))\n",
        "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
        "    # torch.nn.init.zeros_(module.bias)\n",
        "    return\n",
        "\n",
        "\n",
        "class GBN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, virtual_batch_size=128, momentum=0.01):\n",
        "        super(GBN, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.bn = BatchNorm1d(self.input_dim, momentum=momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
        "        res = [self.bn(x_) for x_ in chunks]\n",
        "\n",
        "        return torch.cat(res, dim=0)\n",
        "\n",
        "class TabNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 n_d=64, n_a=64,\n",
        "                 n_steps=5, gamma=1.3,\n",
        "                 n_independent=2, n_shared=2, epsilon=1e-15,\n",
        "                 virtual_batch_size=128, momentum=0.02,\n",
        "                 mask_type=\"sparsemax\"):\n",
        "        super(TabNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.is_multi_task = isinstance(output_dim, list)\n",
        "        self.n_d = n_d\n",
        "        self.n_a = n_a\n",
        "        self.n_steps = n_steps\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.n_independent = n_independent\n",
        "        self.n_shared = n_shared\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.mask_type = mask_type\n",
        "        self.initial_bn = BatchNorm1d(self.input_dim, momentum=0.01)\n",
        "\n",
        "        if self.n_shared > 0:\n",
        "            shared_feat_transform = torch.nn.ModuleList()\n",
        "            for i in range(self.n_shared):\n",
        "                if i == 0:\n",
        "                    shared_feat_transform.append(Linear(self.input_dim,\n",
        "                                                        2*(n_d + n_a),\n",
        "                                                        bias=False))\n",
        "                else:\n",
        "                    shared_feat_transform.append(Linear(n_d + n_a, 2*(n_d + n_a), bias=False))\n",
        "\n",
        "        else:\n",
        "            shared_feat_transform = None\n",
        "\n",
        "        self.initial_splitter = FeatTransformer(self.input_dim, n_d+n_a, shared_feat_transform,\n",
        "                                                n_glu_independent=self.n_independent,\n",
        "                                                virtual_batch_size=self.virtual_batch_size,\n",
        "                                                momentum=momentum)\n",
        "\n",
        "        self.feat_transformers = torch.nn.ModuleList()\n",
        "        self.att_transformers = torch.nn.ModuleList()\n",
        "\n",
        "        for step in range(n_steps):\n",
        "            transformer = FeatTransformer(self.input_dim, n_d+n_a, shared_feat_transform,\n",
        "                                          n_glu_independent=self.n_independent,\n",
        "                                          virtual_batch_size=self.virtual_batch_size,\n",
        "                                          momentum=momentum)\n",
        "            attention = AttentiveTransformer(n_a, self.input_dim,\n",
        "                                             virtual_batch_size=self.virtual_batch_size,\n",
        "                                             momentum=momentum,\n",
        "                                             mask_type=self.mask_type)\n",
        "            self.feat_transformers.append(transformer)\n",
        "            self.att_transformers.append(attention)\n",
        "\n",
        "        if self.is_multi_task:\n",
        "            self.multi_task_mappings = torch.nn.ModuleList()\n",
        "            for task_dim in output_dim:\n",
        "                task_mapping = Linear(n_d, task_dim, bias=False)\n",
        "                initialize_non_glu(task_mapping, n_d, task_dim)\n",
        "                self.multi_task_mappings.append(task_mapping)\n",
        "        else:\n",
        "            self.final_mapping = Linear(n_d, output_dim, bias=False)\n",
        "            initialize_non_glu(self.final_mapping, n_d, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = 0\n",
        "        x = self.initial_bn(x)\n",
        "\n",
        "        prior = torch.ones(x.shape, device=x.device)\n",
        "        M_loss = 0\n",
        "        att = self.initial_splitter(x)[:, self.n_d:]\n",
        "\n",
        "        for step in range(self.n_steps):\n",
        "            M = self.att_transformers[step](prior, att)\n",
        "            M_loss += torch.mean(torch.sum(torch.mul(M, torch.log(M+self.epsilon)),\n",
        "                                           dim=1))\n",
        "            # update prior\n",
        "            prior = torch.mul(self.gamma - M, prior)\n",
        "            # output\n",
        "            masked_x = torch.mul(M, x)\n",
        "            out = self.feat_transformers[step](masked_x)\n",
        "            d = ReLU()(out[:, :self.n_d])\n",
        "            res = torch.add(res, d)\n",
        "            # update attention\n",
        "            att = out[:, self.n_d:]\n",
        "\n",
        "        M_loss /= self.n_steps\n",
        "\n",
        "        if self.is_multi_task:\n",
        "            # Result will be in list format\n",
        "            out = []\n",
        "            for task_mapping in self.multi_task_mappings:\n",
        "                out.append(task_mapping(res))\n",
        "        else:\n",
        "            out = self.final_mapping(res)\n",
        "        return out, M_loss\n",
        "\n",
        "    def forward_masks(self, x):\n",
        "        x = self.initial_bn(x)\n",
        "\n",
        "        prior = torch.ones(x.shape, device=x.device)\n",
        "        M_explain = torch.zeros(x.shape, device=x.device)\n",
        "        att = self.initial_splitter(x)[:, self.n_d:]\n",
        "        masks = {}\n",
        "\n",
        "        for step in range(self.n_steps):\n",
        "            M = self.att_transformers[step](prior, att)\n",
        "            masks[step] = M\n",
        "            # update prior\n",
        "            prior = torch.mul(self.gamma - M, prior)\n",
        "            # output\n",
        "            masked_x = torch.mul(M, x)\n",
        "            out = self.feat_transformers[step](masked_x)\n",
        "            d = ReLU()(out[:, :self.n_d])\n",
        "            # explain\n",
        "            step_importance = torch.sum(d, dim=1)\n",
        "            M_explain += torch.mul(M, step_importance.unsqueeze(dim=1))\n",
        "            # update attention\n",
        "            att = out[:, self.n_d:]\n",
        "\n",
        "        return M_explain, masks\n",
        "\n",
        "class AttentiveTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 virtual_batch_size=128,\n",
        "                 momentum=0.02,\n",
        "                 mask_type=\"entmax\"):\n",
        "        super(AttentiveTransformer, self).__init__()\n",
        "        self.fc = Linear(input_dim, output_dim, bias=False)\n",
        "        initialize_non_glu(self.fc, input_dim, output_dim)\n",
        "        self.bn = GBN(output_dim, virtual_batch_size=virtual_batch_size,\n",
        "                      momentum=momentum)\n",
        "\n",
        "        if mask_type == \"sparsemax\":\n",
        "            # Sparsemax\n",
        "            self.selector = Sparsemax(dim=-1)\n",
        "        elif mask_type == \"entmax\":\n",
        "            # Entmax\n",
        "            self.selector = Entmax15(dim=-1)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Please choose either sparsemax\" +\n",
        "                                      \"or entmax as masktype\")\n",
        "\n",
        "    def forward(self, priors, processed_feat):\n",
        "        x = self.fc(processed_feat)\n",
        "        x = self.bn(x)\n",
        "        x = torch.mul(x, priors)\n",
        "        x = self.selector(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FeatTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, shared_layers, n_glu_independent,\n",
        "                 virtual_batch_size=128, momentum=0.02):\n",
        "        super(FeatTransformer, self).__init__()\n",
        "        params = {\n",
        "            'n_glu': n_glu_independent,\n",
        "            'virtual_batch_size': virtual_batch_size,\n",
        "            'momentum': momentum\n",
        "        }\n",
        "\n",
        "        if shared_layers is None:\n",
        "            # no shared layers\n",
        "            self.shared = torch.nn.Identity()\n",
        "            is_first = True\n",
        "        else:\n",
        "            self.shared = GLU_Block(input_dim, output_dim,\n",
        "                                    first=True,\n",
        "                                    shared_layers=shared_layers,\n",
        "                                    n_glu=len(shared_layers),\n",
        "                                    virtual_batch_size=virtual_batch_size,\n",
        "                                    momentum=momentum)\n",
        "            is_first = False\n",
        "\n",
        "        if n_glu_independent == 0:\n",
        "            # no independent layers\n",
        "            self.specifics = torch.nn.Identity()\n",
        "        else:\n",
        "            spec_input_dim = input_dim if is_first else output_dim\n",
        "            self.specifics = GLU_Block(spec_input_dim, output_dim,\n",
        "                                       first=is_first,\n",
        "                                       **params)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shared(x)\n",
        "        x = self.specifics(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GLU_Block(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, n_glu=2, first=False, shared_layers=None,\n",
        "                 virtual_batch_size=128, momentum=0.02):\n",
        "        super(GLU_Block, self).__init__()\n",
        "        self.first = first\n",
        "        self.shared_layers = shared_layers\n",
        "        self.n_glu = n_glu\n",
        "        self.glu_layers = torch.nn.ModuleList()\n",
        "\n",
        "        params = {\n",
        "            'virtual_batch_size': virtual_batch_size,\n",
        "            'momentum': momentum\n",
        "        }\n",
        "\n",
        "        fc = shared_layers[0] if shared_layers else None\n",
        "        self.glu_layers.append(GLU_Layer(input_dim, output_dim,\n",
        "                                         fc=fc,\n",
        "                                         **params))\n",
        "        for glu_id in range(1, self.n_glu):\n",
        "            fc = shared_layers[glu_id] if shared_layers else None\n",
        "            self.glu_layers.append(GLU_Layer(output_dim, output_dim,\n",
        "                                             fc=fc,\n",
        "                                             **params))\n",
        "\n",
        "    def forward(self, x):\n",
        "        scale = math.sqrt(0.5)\n",
        "        if self.first:  # the first layer of the block has no scale multiplication\n",
        "            x = self.glu_layers[0](x)\n",
        "            layers_left = range(1, self.n_glu)\n",
        "        else:\n",
        "            layers_left = range(self.n_glu)\n",
        "\n",
        "        for glu_id in layers_left:\n",
        "            x = torch.add(x, self.glu_layers[glu_id](x))\n",
        "            x = x*scale\n",
        "        return x\n",
        "\n",
        "\n",
        "class GLU_Layer(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, fc=None,\n",
        "                 virtual_batch_size=128, momentum=0.02):\n",
        "        super(GLU_Layer, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        if fc:\n",
        "            self.fc = fc\n",
        "        else:\n",
        "            self.fc = Linear(input_dim, 2*output_dim, bias=False)\n",
        "        initialize_glu(self.fc, input_dim, 2*output_dim)\n",
        "\n",
        "        self.bn = GBN(2*output_dim, virtual_batch_size=virtual_batch_size,\n",
        "                      momentum=momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.bn(x)\n",
        "        out = torch.mul(x[:, :self.output_dim], torch.sigmoid(x[:, self.output_dim:]))\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-e0_SvHaWIe"
      },
      "source": [
        "验证测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBGkQGn7eUX3"
      },
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install einops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "6b952f00de2b46eebeee22db4a469b1b",
            "faa7e973d51b422cb641994b1dc06794",
            "bc8c2c43f2aa42f5b9846ae4e4d7dd96",
            "cb03de7071a94073a77dc9e0fb87b503",
            "24684ea444504721bcf3aa41b24f8518",
            "b6c981f5386b4fa786cd01817b7f733d",
            "758659a07bf841d3975c9e9a5a2301ad",
            "c3f0778407ff4d7b98e0f11df37e9ef8",
            "c565991532d14c5b822fe9e7be610272",
            "86471e18997945f78b7c1ac1d43aebce",
            "902cfb83958146d38f7c923b68f98dba",
            "d6b452f0cf70406695f165851e137b6a",
            "90c54c8686a74850a32fa9fb881a77e5",
            "43b9e25a1317414b9a48c610e071f28c",
            "2d253a79ef5a4038a4e690390f1340f1",
            "6da4f4157ad842f7aaa6c31c85c0dd07",
            "ffa3a178f3684ca59c47631c61fad37c",
            "3aafcd3def1e407ea2600b29f04e410d",
            "5c28818fec9747dfa772578ce970a225",
            "834d372ae9e04da2b20ad2336180ffc0",
            "68cd09d3243f4f96917eed33eda47ae2",
            "f22588d490b144b8bb795d3927c2bc75",
            "1b9bffea29d34f2191faacf36ed86d7f",
            "4554fc0a6f1c4d248ee5caee06201e05",
            "bc6fe724233a41c1857288f17307db8f",
            "7e2bedd0b9294e2998a72bef0811a762",
            "e2a498ccbaf74c70878a5ea4064a73fd",
            "0f6721f741b043ebade758f437dbf086",
            "c2df067f76c348c888f4a7f77d20f039",
            "e1773040140e4b96bdfc67b385733789",
            "e352382cd36e4c468f17b37fbcfa6cb5",
            "80f26de9e1d74bc0aa1e83408a20ef95"
          ]
        },
        "id": "G-2Xn321aWct",
        "outputId": "2be40bb2-80fa-4278-cbc1-02e618d179d4"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from pytorch_lightning.metrics import Accuracy\n",
        "from einops import rearrange, reduce, repeat\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "class TabDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        self.x = torch.from_numpy(x).type(torch.int64) \n",
        "        self.y = torch.from_numpy(y).type(torch.float32).squeeze() \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx, :], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "class EmbeddingFactory(nn.Module):\n",
        "    def __init__(self, x, dim_out):\n",
        "        super().__init__()\n",
        "        self.dim_out = dim_out\n",
        "        self.module_list = nn.ModuleList(\n",
        "            [nn.Embedding(len(set(np.unique(x[:, col]))), dim_out) for col in range(x.shape[1])])\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = [self.module_list[col](x[:, col]).unsqueeze(2) for col in range(x.shape[1])]\n",
        "        return torch.cat(result, dim=2)\n",
        "\n",
        "train_dataloader = DataLoader(TabDataset(x_dis_train, y_train_np), batch_size = 32, num_workers=6)\n",
        "test_dataloader = DataLoader(TabDataset(x_dis_test, y_test_np), batch_size = 128, num_workers=6)\n",
        "class TrainingModuleV2(pl.LightningModule):\n",
        "    def __init__(self, x, dim_emb, dim_out, penalty=1e-3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.penalty = penalty\n",
        "        self.embedding = EmbeddingFactory(x, dim_emb)\n",
        "        self.backbone = TabNet(x.shape[1]*dim_emb, dim_out, **kwargs)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.loss = nn.BCELoss()\n",
        "        self.accuracy = Accuracy()\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        return self.backbone(x)\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = self.embedding(x)\n",
        "        x = rearrange(x, 'b n e -> b (n e)')\n",
        "        x, _ = self.backbone(x)\n",
        "        x = self.sigmoid(x.squeeze())\n",
        "        loss = self.loss(x.squeeze(), y.type(torch.float32))\n",
        "        acc = self.accuracy(x.squeeze(), y.type(torch.int32))\n",
        "        self.log(\"Validation loss\", loss)\n",
        "        self.log(\"Validation acc\", acc)\n",
        "        return loss, acc\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = self.embedding(x)\n",
        "        x = rearrange(x, 'b n e -> b (n e)')\n",
        "        x, m_loss = self.backbone(x)\n",
        "        x = self.sigmoid(x.squeeze())\n",
        "        loss = self.loss(x, y.type(torch.float32)) - self.penalty*m_loss\n",
        "        acc = self.accuracy(x, y.type(torch.int32))\n",
        "        self.log(\"Training loss\", loss)\n",
        "        self.log(\"Training acc\", acc)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "training_module = TrainingModuleV2(x_dis, 32, 1, n_steps=2, n_independent=4, n_shared=4,)\n",
        "trainer = pl.Trainer(max_epochs=1, gpus=0, progress_bar_refresh_rate=100, val_check_interval=0.5)\n",
        "trainer.fit(training_module, train_dataloader, test_dataloader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | embedding | EmbeddingFactory | 41.7 K\n",
            "1 | backbone  | TabNet           | 1.3 M \n",
            "2 | sigmoid   | Sigmoid          | 0     \n",
            "3 | loss      | BCELoss          | 0     \n",
            "4 | accuracy  | Accuracy         | 0     \n",
            "-----------------------------------------------\n",
            "1.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.3 M     Total params\n",
            "5.277     Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b952f00de2b46eebeee22db4a469b1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c565991532d14c5b822fe9e7be610272",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffa3a178f3684ca59c47631c61fad37c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc6fe724233a41c1857288f17307db8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hv2xHWvhHkU"
      },
      "source": [
        "测试结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si1C0XpWgyjs",
        "outputId": "ace3a665-a106-4dbe-a213-454c9581cad4"
      },
      "source": [
        "trainer.callback_metrics"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Training acc': tensor(0.8125),\n",
              " 'Training loss': tensor(0.5555),\n",
              " 'Validation acc': tensor(0.6037),\n",
              " 'Validation loss': tensor(0.6835)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}