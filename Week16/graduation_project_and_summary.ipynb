{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graduation-project-and-summary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "19q8QDL_OZOTYcctyxCQ7evSktGPx2bt9",
      "authorship_tag": "ABX9TyOartsFmKD8Cylut/xNSaao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wuliubao/ML-000/blob/main/Week16/graduation_project_and_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxzojPzSPqCs"
      },
      "source": [
        "**毕业设计**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjqnHl1mFSXk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bKn99ZtK4Il"
      },
      "source": [
        "#处理数据\n",
        "df_train = pd.read_csv(\"train_final.csv\")\n",
        "df_test = pd.read_csv(\"test_final.csv\")\n",
        "\n",
        "df_train.fillna(0,inplace=True)\n",
        "df_test.fillna(0,inplace=True)\n",
        "\n",
        "seed = 42 # for the same data division\n",
        "\n",
        "kf = KFold(n_splits=5, random_state=seed,shuffle=True)\n",
        "X_train = df_train.drop(columns=['loan_status']).values\n",
        "Y_train = df_train['loan_status'].values.astype(int)\n",
        "\n",
        "X_test = df_test.drop(columns=['loan_status']).values\n",
        "Y_test = df_test['loan_status'].values.astype(int)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i0VoF9CGrFE"
      },
      "source": [
        "# 一.构建衍生变量\n",
        "\n",
        "1.组合新特征：根据业务逻辑，构造变量：还款压力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_1c6XKVOJj0"
      },
      "source": [
        "#把每月的还款:continuous_installment和月收入即年收入/12:continuous_annual_inc/12比值，得到结果即还款的压力\n",
        "X_train['pressure'] = X_train['continuous_installment'] / (X_train['continuous_annual_inc'] / 12)\n",
        "X_test['pressure'] = X_test['continuous_installment'] / (X_test['continuous_annual_inc'] / 12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2nvWHVOVmc"
      },
      "source": [
        "2.数据处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aduwBhttIrA"
      },
      "source": [
        "#对大数据取对数展开信息\n",
        "X_train['log_annual_inc'] = np.floor(np.log10(X_train['continuous_annual_inc'])\n",
        "X_test['log_annual_inc'] = np.floor(np.log10(X_test['continuous_annual_inc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFysRYxftD8Y"
      },
      "source": [
        "3.特征离散化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kEincnxtIKR"
      },
      "source": [
        "# 等宽离散\n",
        "k = 5 # 分为5个等宽区间\n",
        "X_train['area_dti'] = pd.cut(X_train['continuous_dti'], k, labels=range(k)])\n",
        "X_test['area_dti'] = pd.cut(X_test['continuous_dti'], k, labels=range(k)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWuP8HfQRucF"
      },
      "source": [
        "# 二.传统模型：逻辑回归、高斯朴素贝叶斯、随机森林\n",
        "\n",
        "1.逻辑回归"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga72_8xTR16z",
        "outputId": "753d2242-dacb-4717-fdfa-c633c542ab78"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "lr_model = linear_model.LogisticRegression(C=1e9)\n",
        "\n",
        "lr_model.fit(X_train, Y_train)\n",
        "lr_model.score(X_test, Y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BFk_OdIXpk0"
      },
      "source": [
        "2.高斯朴素贝叶斯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlHc4pKqYQD7",
        "outputId": "7bcc7cf5-3db0-432e-9891-cdd3e33aeb0f"
      },
      "source": [
        "from sklearn import naive_bayes\n",
        "\n",
        "bayes_clf = naive_bayes.GaussianNB()\n",
        "bayes_clf.fit(X_train, Y_train)\n",
        "bayes_clf.score(X_test, Y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.90478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc7pJzYEYnmC"
      },
      "source": [
        "3.随机森林"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8W8G0mShwlD",
        "outputId": "bc8389b5-15af-41f4-906c-7254ed6d18d4"
      },
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "rf_clf = ensemble.RandomForestClassifier()\n",
        "rf_clf.fit(X_train, Y_train)\n",
        "rf_clf.score(X_test, Y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7pjsFiqR1DM"
      },
      "source": [
        "# 三.集成学习：基于lightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8lIc8u3ZOeE"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X_train.shape, Y_train.shape\n",
        "\n",
        "lgb_train = lgb.Dataset(x_train, y_train, free_raw_data=False)\n",
        "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train, free_raw_data=False)\n",
        "\n",
        "five_fold_data = []\n",
        "\n",
        "for train_index, eval_index in kf.split(X_train):\n",
        "    x_train, x_eval = X_train[train_index], X_train[eval_index]\n",
        "    y_train, y_eval = Y_train[train_index], Y_train[eval_index]\n",
        "    \n",
        "    five_fold_data.append([(x_train, y_train), (x_eval, y_eval)])\n",
        "\n",
        "def get_model(param):\n",
        "    model_list = []\n",
        "    for idx, [(x_train, y_train), (x_eval, y_eval)] in enumerate(five_fold_data):\n",
        "        print('{}-th model is training:'.format(idx))\n",
        "        train_data = lgb.Dataset(x_train, label=y_train)\n",
        "        validation_data = lgb.Dataset(x_eval, label=y_eval)\n",
        "        bst = lgb.train(param, train_data, valid_sets=[validation_data])\n",
        "        model_list.append(bst)\n",
        "    return model_list\n",
        "\n",
        "param_base = {'num_leaves': 31, 'objective': 'binary', 'metric': 'binary', 'num_round':1000}\n",
        "\n",
        "param_fine_tuning = {'num_thread': 8,'num_leaves': 128, 'metric': 'binary', 'objective': 'binary', 'num_round': 1000, \n",
        "                     'learning_rate': 3e-3, 'feature_fraction': 0.6, 'bagging_fraction': 0.8}\n",
        "\n",
        "\n",
        "# base param train\n",
        "param_base_model = get_model(param_base)\n",
        "\n",
        "# param fine tuning\n",
        "param_fine_tuning_model = get_model(param_fine_tuning)\n",
        "\n",
        "def test_model(model_list):\n",
        "    data = X_test\n",
        "    five_fold_pred = np.zeros((5, len(X_test)))\n",
        "    for i, bst in enumerate(model_list):\n",
        "        ypred = bst.predict(data, num_iteration=bst.best_iteration)\n",
        "        five_fold_pred[i] = ypred\n",
        "    ypred_mean = (five_fold_pred.mean(axis=-2)>0.5).astype(int)\n",
        "    return accuracy_score(ypred_mean, Y_test)\n",
        "\n",
        "base_score = test_model(param_base_model)\n",
        "fine_tuning_score = test_model(param_fine_tuning_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqWndAIEraVr",
        "outputId": "52a43686-af7f-4ef3-eae6-f913845c77f3"
      },
      "source": [
        "print('base: {}, fine tuning: {}'.format(base_score, fine_tuning_score))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "base: 0.91626, fine tuning: 0.9176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ0zMbLnR1ET"
      },
      "source": [
        "# 四.深度学习：基于tabNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW6GhC2PitNr"
      },
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRmq7an4ZwN7",
        "outputId": "97127069-b712-467d-a09a-7f8ee3f58d87"
      },
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
        "\n",
        "tabnet_clf = TabNetClassifier()\n",
        "tabnet_clf.fit(X_train, Y_train, max_epochs=50, patience=5)\n",
        "pre_test = tabnet_clf.predict(X_test)\n",
        "accuracy_score(Y_test, pre_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cpu\n",
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 0.3637  |  0:00:07s\n",
            "epoch 1  | loss: 0.22322 |  0:00:15s\n",
            "epoch 2  | loss: 0.21633 |  0:00:22s\n",
            "epoch 3  | loss: 0.21387 |  0:00:30s\n",
            "epoch 4  | loss: 0.21347 |  0:00:37s\n",
            "epoch 5  | loss: 0.21252 |  0:00:44s\n",
            "epoch 6  | loss: 0.21078 |  0:00:52s\n",
            "epoch 7  | loss: 0.21084 |  0:00:59s\n",
            "epoch 8  | loss: 0.20861 |  0:01:06s\n",
            "epoch 9  | loss: 0.20852 |  0:01:13s\n",
            "epoch 10 | loss: 0.20786 |  0:01:20s\n",
            "epoch 11 | loss: 0.20745 |  0:01:27s\n",
            "epoch 12 | loss: 0.20732 |  0:01:34s\n",
            "epoch 13 | loss: 0.20591 |  0:01:41s\n",
            "epoch 14 | loss: 0.20517 |  0:01:48s\n",
            "epoch 15 | loss: 0.2058  |  0:01:55s\n",
            "epoch 16 | loss: 0.20533 |  0:02:02s\n",
            "epoch 17 | loss: 0.2057  |  0:02:09s\n",
            "epoch 18 | loss: 0.20717 |  0:02:16s\n",
            "epoch 19 | loss: 0.2051  |  0:02:23s\n",
            "epoch 20 | loss: 0.2058  |  0:02:30s\n",
            "epoch 21 | loss: 0.20426 |  0:02:37s\n",
            "epoch 22 | loss: 0.20468 |  0:02:44s\n",
            "epoch 23 | loss: 0.20402 |  0:02:51s\n",
            "epoch 24 | loss: 0.20322 |  0:02:58s\n",
            "epoch 25 | loss: 0.20491 |  0:03:05s\n",
            "epoch 26 | loss: 0.2044  |  0:03:12s\n",
            "epoch 27 | loss: 0.20508 |  0:03:19s\n",
            "epoch 28 | loss: 0.20347 |  0:03:26s\n",
            "epoch 29 | loss: 0.20363 |  0:03:33s\n",
            "epoch 30 | loss: 0.20282 |  0:03:40s\n",
            "epoch 31 | loss: 0.20299 |  0:03:47s\n",
            "epoch 32 | loss: 0.20217 |  0:03:54s\n",
            "epoch 33 | loss: 0.20364 |  0:04:01s\n",
            "epoch 34 | loss: 0.20182 |  0:04:08s\n",
            "epoch 35 | loss: 0.20427 |  0:04:15s\n",
            "epoch 36 | loss: 0.20672 |  0:04:23s\n",
            "epoch 37 | loss: 0.21037 |  0:04:30s\n",
            "epoch 38 | loss: 0.21438 |  0:04:36s\n",
            "epoch 39 | loss: 0.2105  |  0:04:43s\n",
            "epoch 40 | loss: 0.21215 |  0:04:50s\n",
            "epoch 41 | loss: 0.20975 |  0:04:57s\n",
            "epoch 42 | loss: 0.20867 |  0:05:04s\n",
            "epoch 43 | loss: 0.20881 |  0:05:11s\n",
            "epoch 44 | loss: 0.20634 |  0:05:18s\n",
            "epoch 45 | loss: 0.20551 |  0:05:25s\n",
            "epoch 46 | loss: 0.20523 |  0:05:32s\n",
            "epoch 47 | loss: 0.20584 |  0:05:39s\n",
            "epoch 48 | loss: 0.20428 |  0:05:45s\n",
            "epoch 49 | loss: 0.20418 |  0:05:52s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91412"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYmEbY4bSdPk"
      },
      "source": [
        "**毕业总结**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvju-hyfSe9U"
      },
      "source": [
        "通过这几个月跟在王老师后面的学习，收获非常多，在对整个机器学习的路上进步很多。总结了一下：\n",
        "\n",
        "1.   对机器学习知识面整体有个概论，对业务实现有个流程了解。\n",
        "2.   所需的数学知识学习有了思路\n",
        "3.   手写代码，加深了对机器学习的理解\n",
        "\n",
        "最后感谢王老师、助教、班主任同学的帮助，让我打开了机器学习之门，后面学习的路还能艰辛和漫长，需要继续努力！\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}